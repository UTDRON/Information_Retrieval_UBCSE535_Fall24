{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba6771da-75c3-498e-84d4-8b0c910f0a29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/pratik/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/pratik/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "import sys\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "49fd1135-52fa-4667-80fd-93654ce62b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# f = open(\"data/input_corpus.txt\")\n",
    "f = open(\"data/test_corpus.txt\")\n",
    "# for line in range(5):\n",
    "#     print(f[line])\n",
    "data = []\n",
    "for line in f:\n",
    "    data.append({int(line[:line.find(\"\\t\")]) : line[line.find(\"\\t\")+1:]})\n",
    "f.close()\n",
    "sorted_data = sorted(data, key=lambda x: list(x.keys())[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a959e61f-9334-4c7a-b0e6-08ba8bd28199",
   "metadata": {},
   "outputs": [],
   "source": [
    "lowercased_data = [{k: v.lower()} for d in sorted_data for k, v in d.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1454ed36-a377-4629-ae31-bfbcc36ffc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    cleaned_text = re.sub(r'-', '', text)\n",
    "    # cleaned_text = re.sub(r\"'\", '', cleaned_text)\n",
    "    cleaned_text = re.sub(r'[^a-zA-Z0-9 ]', ' ', cleaned_text)\n",
    "    cleaned_text = re.sub(r'\\s+', ' ', cleaned_text)\n",
    "    cleaned_text = cleaned_text.strip()\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "11810191-e8b4-4e0c-9692-cfe3af7ad779",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data = [{k: clean_text(v)} for d in lowercased_data for k, v in d.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "45e25b39-056c-45a7-b56b-15a51fc4a1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_data = [{k: v.split()} for d in cleaned_data for k, v in d.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "eb1a2025-857c-45a8-8102-40d5db57fefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words_removed_data = [{k: [word for word in v if word.lower() not in stop_words]} for d in tokenized_data for k, v in d.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9a32b8c3-4592-4cce-ae17-27686a85bc6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{1: ['hello', 'world']},\n",
       " {2: ['hello', 'hi', 'world', 'world', 'hello', 'jack']},\n",
       " {3: ['even', 'know']},\n",
       " {4: ['common', 'known', 'thing']},\n",
       " {5: ['hello', 'jack']},\n",
       " {6: ['let', 'meet', 'cafe']},\n",
       " {7: ['go', 'swim', 'meet', 'monday']},\n",
       " {8: ['swim', 'good', 'health']},\n",
       " {9: ['hello', 'go', 'swim']},\n",
       " {10: ['random', 'text']},\n",
       " {11: ['random', 'text', 'text']},\n",
       " {12: ['random', 'text', 'randomli', 'strike', 'back']}]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "porter_stemmer = PorterStemmer()\n",
    "stemmed_data = [{k: [porter_stemmer.stem(word) for word in v]} for d in stop_words_removed_data for k, v in d.items()]\n",
    "stemmed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "64d7d78f-009b-4380-9f48-31b7f997dc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PostingNode:\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.next = None\n",
    "\n",
    "class PostingsList:\n",
    "    def __init__(self):\n",
    "        self.head = None\n",
    "\n",
    "    def insert_at_beginning(self, data):\n",
    "        new_node = PostingNode(data)\n",
    "        if self.head == None:\n",
    "            self.head = new_node\n",
    "        else:\n",
    "            new_node.next = self.head\n",
    "            self.head = new_node\n",
    "\n",
    "    def insert_at_last(self, data):\n",
    "        new_node = PostingNode(data)\n",
    "        if self.head == None:\n",
    "            self.head = new_node\n",
    "            return\n",
    "\n",
    "        running_node = self.head\n",
    "        while running_node.next:\n",
    "            running_node = running_node.next\n",
    "\n",
    "        running_node.next = new_node\n",
    "\n",
    "    def print_postings_list(self):\n",
    "        running_node = self.head\n",
    "        print(\"[ \",end = \"\")\n",
    "        while running_node:\n",
    "            print(running_node.data,end = \", \")\n",
    "            running_node = running_node.next\n",
    "        print(\"]\")\n",
    "\n",
    "    def obtain_postings_list(self):\n",
    "        postings_list           = []\n",
    "        running_node            = self.head\n",
    "        while running_node:\n",
    "            postings_list.append(running_node.data)\n",
    "            running_node        = running_node.next\n",
    "        \n",
    "        return postings_list\n",
    "        \n",
    "vocabulary_mapping = {}\n",
    "for d in stemmed_data:\n",
    "    for key, value in d.items():\n",
    "        for word in value:\n",
    "            if word in vocabulary_mapping:\n",
    "                postings_list = vocabulary_mapping[word]\n",
    "            else:\n",
    "                postings_list = PostingsList()\n",
    "                vocabulary_mapping[word] = postings_list\n",
    "            \n",
    "            postings_list.insert_at_last(key)\n",
    "                "
   ]
  },
  {
   "cell_type": "raw",
   "id": "9ce5bb5e-fe36-4a75-a0e3-7bbf5e902178",
   "metadata": {},
   "source": [
    "for key, value in vocabulary_mapping.items():\n",
    "    print(key,end = \",\")\n",
    "    value.print_postings_list()\n",
    "    # print(value)\n",
    "    # print(key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a3ace717-b91b-40cb-9137-45e6e1354d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "queryset = {'swim', 'hello', 'random', 'go', 'world'}\n",
    "postingsList = {'postingsList': {}}\n",
    "for item in queryset:\n",
    "    try:\n",
    "        postingsList['postingsList'][item] = vocabulary_mapping[item].obtain_postings_list()\n",
    "        # print({item: vocabulary_mapping[item].obtain_postings_list()})\n",
    "    except:\n",
    "        # print({item: []})\n",
    "        postingsList['postingsList'][item] = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a08e0196-cdc4-4598-8326-e9f980e26780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hello': [1, 2, 2, 5, 9]}\n",
      "{'world': [1, 2, 2]}\n",
      "{'hi': [2]}\n",
      "{'jack': [2, 5]}\n",
      "{'even': [3]}\n",
      "{'know': [3]}\n",
      "{'common': [4]}\n",
      "{'known': [4]}\n",
      "{'thing': [4]}\n",
      "{'let': [6]}\n",
      "{'meet': [6, 7]}\n",
      "{'cafe': [6]}\n",
      "{'go': [7, 9]}\n",
      "{'swim': [7, 8, 9]}\n",
      "{'monday': [7]}\n",
      "{'good': [8]}\n",
      "{'health': [8]}\n",
      "{'random': [10, 11, 12]}\n",
      "{'text': [10, 11, 11, 12]}\n",
      "{'randomli': [12]}\n",
      "{'strike': [12]}\n",
      "{'back': [12]}\n"
     ]
    }
   ],
   "source": [
    "for word, obj in vocabulary_mapping.items():\n",
    "    print({word: obj.obtain_postings_list()})"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0c732e5e-2061-4193-9977-6420d59bc22d",
   "metadata": {},
   "source": [
    "import math\n",
    "num = 65\n",
    "if type(math.sqrt(num)) == int:\n",
    "    print(math.floor(math.sqrt(num)) - 1)\n",
    "else:\n",
    "    print(math.floor(math.sqrt(num)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2e0c8c43-5ca2-4aea-90e2-2a0381bc9e7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello', 'swimming']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = \"hello swimming hello\"\n",
    "list(set(test.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8578c077-331f-4711-b734-842074e507e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "ptr1 = [3,2]\n",
    "ptr2 = [3,5]\n",
    "if not (ptr1 and ptr2):\n",
    "    print(\"True\")\n",
    "else:\n",
    "    print(\"False\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c61878b9-2f60-44f5-a61f-4e1776de10e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hello swimming hello world random swimming swimming going']\n"
     ]
    }
   ],
   "source": [
    "queries = {'queries': [\"hello swimming\", \"hello world\", \"random swimming\", \"swimming going\"]}\n",
    "\n",
    "# Concatenate all the queries into one string, separated by a space\n",
    "concatenated_queries = [\" \".join(queries['queries'])]\n",
    "\n",
    "print(concatenated_queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1be7d4-3ca0-454a-8178-1b48f53aada2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
